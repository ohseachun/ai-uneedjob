import { ChatOpenAI } from "@langchain/openai";
import { ChatAnthropic } from "@langchain/anthropic";
import { HumanMessage } from "@langchain/core/messages";
import * as readline from "readline";
import * as dotenv from "dotenv";

dotenv.config();


const rl = readline.createInterface({
    input: process.stdin,
    output: process.stdout,
})

const gpt = new ChatOpenAI({modelName: "gpt-4o-mini", temperature: 0.3});
const claude = new ChatAnthropic({modelName: "claude-3-5-sonnet-20241022", temperature: 0.5});

rl.question("ì´ë©”ì¼ ë³¸ë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.", async (inputstring:string): Promise<void> => {
    
    const gptSummary = await gpt.invoke([
        new HumanMessage(`ë‹¤ìŒ ì´ë©”ì¼ì„ í•œ ë¬¸ë‹¨ìœ¼ë¡œ ìš”ì•½í•´ì¤˜:\n${inputstring}`)
    ])

    console.log("GPT ìš”ì•½:", gptSummary.content);


    // refinedëŠ” "ë” ë‹¤ë“¬ì–´ì§„" ë˜ëŠ” "ë” ìì—°ìŠ¤ëŸ½ê²Œ ì •ë¦¬ëœ" ê²°ê³¼ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.
    const refined = await claude.invoke([
        new HumanMessage(`ë‹¤ìŒ ë¬¸ì¥ì„ ë” ìì—°ìŠ¤ëŸ½ê²Œ ì •ë¦¬í•´ì¤˜:\n${inputstring}`)
    ])

    console.log("\nğŸ“ ìš”ì•½:", refined.content);
    rl.close();

})
