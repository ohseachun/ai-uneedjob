/**
 * ë‰´ìŠ¤ ìš”ì•½ ë° í‚¤ì›Œë“œ ì¶”ì¶œ ì˜ˆì œ
 * 
 * í•™ìŠµ ëª©í‘œ:
 * 1. LangChainì˜ Document í´ë˜ìŠ¤ ì‚¬ìš©ë²• í•™ìŠµ
 * 2. loadSummarizationChainì„ ì´ìš©í•œ í…ìŠ¤íŠ¸ ìš”ì•½ ì²´ì¸ êµ¬í˜„
 * 3. LLMChainì„ ì´ìš©í•œ êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬
 * 4. ì™¸ë¶€ API (ë‰´ìŠ¤ ì›¹ì‚¬ì´íŠ¸) ë°ì´í„° ìˆ˜ì§‘ ë° ì²˜ë¦¬
 * 5. ì²´ì¸ ì—°ê²° (ìš”ì•½ â†’ í‚¤ì›Œë“œ ì¶”ì¶œ) ì›Œí¬í”Œë¡œìš° êµ¬í˜„
 * 6. í™˜ê²½ ë³€ìˆ˜ë¥¼ í†µí•œ API í‚¤ ê´€ë¦¬
 */

// í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (API í‚¤ ë“± ë¯¼ê°í•œ ì •ë³´ ê´€ë¦¬)
import * as dotenv from "dotenv";
dotenv.config();

// LangChain í•µì‹¬ ì»´í¬ë„ŒíŠ¸ë“¤ import
import { ChatOpenAI } from "@langchain/openai";  // OpenAI GPT ëª¨ë¸ ì‚¬ìš©
import { loadSummarizationChain } from "langchain/chains";  // í…ìŠ¤íŠ¸ ìš”ì•½ ì²´ì¸
import { Document } from "langchain/document";  // ë¬¸ì„œ ê°ì²´ (í…ìŠ¤íŠ¸ë¥¼ LangChain í˜•ì‹ìœ¼ë¡œ ë³€í™˜)
import { PromptTemplate } from "@langchain/core/prompts";  // êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
import { LLMChain } from "langchain/chains";  // ê¸°ë³¸ LLM ì²´ì¸ (í”„ë¡¬í”„íŠ¸ + ëª¨ë¸)

// ë¡œì»¬ ëª¨ë“ˆ import
import { keywordExtractionPrompt } from "./prompts";  // í‚¤ì›Œë“œ ì¶”ì¶œìš© í”„ë¡¬í”„íŠ¸
import { fetchNewsText } from "./utils";  // ì›¹ ìŠ¤í¬ë˜í•‘ ìœ í‹¸ë¦¬í‹°

/**
 * ë‰´ìŠ¤ URLì„ ë°›ì•„ì„œ ìš”ì•½í•˜ê³  í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ëŠ” ë©”ì¸ í•¨ìˆ˜
 * @param url - ìš”ì•½í•  ë‰´ìŠ¤ ê¸°ì‚¬ì˜ URL
 */
async function summarizeNews(url: string) {
  // 1ë‹¨ê³„: ì›¹ ìŠ¤í¬ë˜í•‘ìœ¼ë¡œ ë‰´ìŠ¤ í…ìŠ¤íŠ¸ ìˆ˜ì§‘
  const rawText = await fetchNewsText(url);

  // 2ë‹¨ê³„: OpenAI ëª¨ë¸ ì„¤ì •
  const model = new ChatOpenAI({
    temperature: 0.2,  // ë‚®ì€ temperatureë¡œ ì¼ê´€ëœ ê²°ê³¼ ìƒì„±
    modelName: "gpt-4o",  // ìµœì‹  GPT-4 ëª¨ë¸ ì‚¬ìš©
    openAIApiKey: process.env.OPENAI_API_KEY,  // í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ
  });

  // 3ë‹¨ê³„: í…ìŠ¤íŠ¸ë¥¼ LangChain Document ê°ì²´ë¡œ ë³€í™˜
  // DocumentëŠ” LangChainì´ í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•  ë•Œ ì‚¬ìš©í•˜ëŠ” í‘œì¤€ í˜•ì‹
  const docs = [new Document({ pageContent: rawText })];
  
  // 4ë‹¨ê³„: ìš”ì•½ ì²´ì¸ ìƒì„± ë° ì‹¤í–‰
  // loadSummarizationChainì˜ typeì—ëŠ” ì—¬ëŸ¬ ë°©ì‹ì´ ìˆìŒ:
  // - "map_reduce": ê¸´ í…ìŠ¤íŠ¸ë¥¼ ì—¬ëŸ¬ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ê°ê° ìš”ì•½(map)í•œ ë’¤, ê·¸ ê²°ê³¼ë¥¼ ë‹¤ì‹œ í•©ì³ ìµœì¢… ìš”ì•½(reduce)í•¨. ëŒ€ìš©ëŸ‰ í…ìŠ¤íŠ¸ì— ì í•©.
  // - "stuff": ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ í•œ ë²ˆì— LLMì— ì…ë ¥(stuff)í•˜ì—¬ ìš”ì•½. ì§§ì€ í…ìŠ¤íŠ¸ì— ë¹ ë¥´ê³  ê°„ë‹¨í•˜ê²Œ ì‚¬ìš©.
  // - "refine": ì²« ì²­í¬ë¥¼ ìš”ì•½í•œ ë’¤, ë‹¤ìŒ ì²­í¬ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì¶”ê°€í•˜ë©° ìš”ì•½ì„ ì ì§„ì ìœ¼ë¡œ ê°œì„ (refine)í•¨. ë§¥ë½ì„ ëˆ„ì í•˜ë©° ì •êµí•˜ê²Œ ìš”ì•½.
  // ê° ë°©ì‹ì˜ íŠ¹ì§•:
  //   - map_reduce: ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥, ëŒ€ìš©ëŸ‰ì— ê°•í•¨, ë‹¤ì†Œ ìš”ì•½ì´ ë‹¨ìˆœí•´ì§ˆ ìˆ˜ ìˆìŒ.
  //   - stuff: ê°€ì¥ ë¹ ë¥´ê³  ê°„ë‹¨, ì…ë ¥ ê¸¸ì´ ì œí•œì— ì£¼ì˜.
  //   - refine: ë§¥ë½ì„ ëˆ„ì í•´ ë” ì •êµí•œ ìš”ì•½ ê°€ëŠ¥, ì²˜ë¦¬ ì†ë„ëŠ” ëŠë¦´ ìˆ˜ ìˆìŒ.
  const chain = await loadSummarizationChain(model, { type: "map_reduce" });
  const summaryResult = await chain.call({ input_documents: docs });
  const summary = summaryResult?.text;
  
  console.log("âœ… ìš”ì•½ ê²°ê³¼:\n", summary);

  // 5ë‹¨ê³„: í‚¤ì›Œë“œ ì¶”ì¶œì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
  const prompt = new PromptTemplate({
    inputVariables: ["summary"],  // í”„ë¡¬í”„íŠ¸ì—ì„œ ì‚¬ìš©í•  ë³€ìˆ˜ëª…
    template: keywordExtractionPrompt,  // prompts.tsì—ì„œ ì •ì˜ëœ í…œí”Œë¦¿
  });

  // 6ë‹¨ê³„: í‚¤ì›Œë“œ ì¶”ì¶œ ì²´ì¸ ìƒì„± ë° ì‹¤í–‰
  // LLMChain: í”„ë¡¬í”„íŠ¸ + ëª¨ë¸ì„ ì—°ê²°í•˜ëŠ” ê¸°ë³¸ ì²´ì¸
  const extractChain = new LLMChain({ llm: model, prompt });
  const keywordsResult = await extractChain.call({ summary });

  console.log("\nğŸ“Œ ìš”ì  ë° í‚¤ì›Œë“œ ì¶”ì¶œ:\n", keywordsResult.text);
}

// í…ŒìŠ¤íŠ¸ ì‹¤í–‰
const newsUrl = "https://www.bbc.com/news/technology-66208730";
summarizeNews(newsUrl);